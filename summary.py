import pandas as pd
from rich.console import Console
from rich.table import Table
from datetime import datetime
import os

# ---------------- CONFIG ----------------
# Path to the CSV generated by your scraper
CSV_FILE = r"D:\CultureCircle-Scraper\CultureCircle-Scraper\culturecircle_scrape_20250918_094210\culturecircle_products_20250918_094210.csv"  # <-- replace with actual CSV path

console = Console()

# ---------------- LOAD DATA ----------------
if not os.path.exists(CSV_FILE):
    console.print(f"[red]CSV file not found:[/red] {CSV_FILE}")
    exit(1)

df = pd.read_csv(CSV_FILE)

# ---------------- SUMMARY METRICS ----------------
total_products = len(df)
successful_extractions = df.dropna(subset=["product_name", "price"]).shape[0]
failed_extractions = total_products - successful_extractions
categories_processed = df["category"].nunique()
success_rate = round((successful_extractions / total_products) * 100, 2)
images_downloaded = df["image_url"].dropna().shape[0]

# ---------------- PRODUCTS BY CATEGORY ----------------
products_by_category = df.groupby("category").size().sort_values(ascending=False)

# ---------------- TOP BRANDS ----------------
top_brands = df.groupby("brand").size().sort_values(ascending=False).head(10)

# ---------------- PRINT SUMMARY ----------------
console.print("\n[bold green]Final Scraping Summary[/bold green]\n")
console.print(f"Total Products Scraped: [bold]{total_products}[/bold]")
console.print(f"Successful Extractions: [bold green]{successful_extractions}[/bold green]")
console.print(f"Failed Extractions: [bold red]{failed_extractions}[/bold red]")
console.print(f"Categories Processed: [bold]{categories_processed}[/bold]")
console.print(f"Success Rate: [bold]{success_rate}%[/bold]")
console.print(f"Images Downloaded: [bold]{images_downloaded}[/bold]")

# ---------------- PRODUCTS BY CATEGORY TABLE ----------------
table_cat = Table(title="Products by Category")
table_cat.add_column("Category", style="cyan", justify="left")
table_cat.add_column("Count", style="magenta", justify="right")
for cat, count in products_by_category.items():
    table_cat.add_row(str(cat), str(count))
console.print(table_cat)

# ---------------- TOP BRANDS TABLE ----------------
table_brand = Table(title="Top Brands")
table_brand.add_column("Brand", style="cyan", justify="left")
table_brand.add_column("Products", style="magenta", justify="right")
for brand, count in top_brands.items():
    table_brand.add_row(str(brand), str(count))
console.print(table_brand)

# ---------------- OPTIONAL: SAVE SUMMARY ----------------
SUMMARY_FILE = os.path.join(os.path.dirname(CSV_FILE), "scraper_summary.txt")
with open(SUMMARY_FILE, "w", encoding="utf-8") as f:
    f.write("Final Scraping Summary\n")
    f.write(f"Total Products Scraped: {total_products}\n")
    f.write(f"Successful Extractions: {successful_extractions}\n")
    f.write(f"Failed Extractions: {failed_extractions}\n")
    f.write(f"Categories Processed: {categories_processed}\n")
    f.write(f"Success Rate: {success_rate}%\n")
    f.write(f"Images Downloaded: {images_downloaded}\n\n")
    f.write("Products by Category:\n")
    f.write(products_by_category.to_string())
    f.write("\n\nTop Brands:\n")
    f.write(top_brands.to_string())

console.print(f"\n[bold green]Summary saved to:[/bold green] {SUMMARY_FILE}")
